IN an ideal motoring world, Amnon Shashua acknowledges, there would be no need for the EyeQ chip, a processor that analyzes signals from automobile-mounted cameras to warn drivers of potential collisions or other dangerous situations.
''If you're very vigilant and very alert, you don't need a thing to help you,'' said Dr. Shashua, the chairman and chief scientist of MobilEye, a company based in the Netherlands that produces EyeQ. ''Your visual processing is much better than any computer.''
For many people, of course, driving is an activity that may overlap with other tasks like dialing cellphones, twiddling radio dials and restoring peace among children. For those situations, Dr. Shashua said, a computerized camera becomes ''another eye helping the driver.''
Systems that use computer analysis to help prevent accidents are already standard in some vehicles. A relatively common example is the cruise-control system that uses radar beams to maintain a safe gap between cars.
But the price of radar technology -- unlike, say, CD players -- is not likely to become feasible soon for use in more plebian cars and vans. The cost issue, along with some inherent limitations, has generated interest in using inexpensive cameras based on complementary metal oxide semiconductor technology, or CMOS, to scan the road for danger.
Dr. Shashua, who is also the chairman of the school of engineering and computer science at the Hebrew University of Jerusalem, first became aware of such interest through his involvement in a different commercial venture in the 1990's.
At that time, he had set up a company to exploit the expertise he had acquired in computer vision and machine learning at the Massachusetts Institute of Technology's artificial-intelligence lab. That venture makes costly camera-based inspection machines used by automakers to check the dimensions and other properties of parts.
But Dr. Shashua said there was an enormous difference between measuring car bumpers and dashboards as they move along the assembly line and asking a computer to deal with everything that comes roaring into an car's field of view.
''This is a big challenge,'' he said. ''When you put a camera into a car that's moving along, you have control over nothing.''
Compounding the challenge, he added, such a camera system must be reasonably sophisticated, to avoid alienating drivers with false or excessively cautious alerts.
The first step in developing the system, Dr. Shashua said, was to create thousands of images of the crucial visual elements that the system would need to recognize, like other vehicles, road markings, guard rails, cyclists and pedestrians.
Similarly, the software had to be loaded with thousands of images of objects it could safely ignore, like trees. From there, it then was mostly a matter of testing and refining the system, first in a lab and then in cars.
''It is learning by example,'' Dr. Shashua said of the system.
Of course, a good deal of re-education was needed during the testing period. Among other things, the system initially assumed that pedestrians (which, along with cyclists, are the most difficult things to identify) dressed in white were lane markings.
The system also needed a way to judge distances between the car and other objects. One approach would be to mimic the binocular vision of humans by combining images from two cameras. But Dr. Shashua rejected that because of the cost.
As part of his general computer-vision research, Dr. Shashua had found that the importance of binocular vision for humans declines with distance. ''You can drive a car with one eye,'' he said, ''although it's not very comfortable at first.''
One-eyed driving is possible because the brain can judge the proximity of moving objects by their increasing or decreasing size on the eye's retina. For his digital invention, Dr. Shashua adopted the concept.
Collaborating with big auto-parts suppliers and the automakers themselves,MobilEye is developing various car systems. Dr. Shashua expects one of the early applications to be a camera that warn drivers if they are wandering within their lane on the highway. If a turn indicator is not operating and the camera detects that the car is moving out of its lane, an electronically generated rumble will sound as a warning.
Later, he anticipates that the systems will detect imminent collisions, sound warnings and try to reduce the chance of injury by taking steps like locking seat belts.
Two cars recently introduced only in Japan incorporate some of these ideas. A two-camera system in the Subaru Legacy warns of dangerous situations. One version of the Honda Inspire (which strongly resembles the Accord) uses a single camera to adjust the steering automatically if the car begins wandering within a lane.
Cameras, however, are unlikely to replace radar altogether.
''Radar has the ability to measure distances very accurately,'' said Karl Naab, the head of intelligent sensor development at the BMW Group. ''The camera has the advantage of being able to detect road surfaces and to see the white lines. It's also difficult, in some cases, for radar to identify different types of objects.''
In North America, truckers rather than regular motorists may become the first drivers to benefit from in-car camera systems. East West Express, a trucking company based in Calgary, Alberta, is testing a safety system that uses the EyeQ chip.
Thomas deWaal, the company's president, said he was so impressed with the results that his plans now go beyond outfitting all 55 of his trucks. He has started a separate company to build and market the systems, which use the camera to gather data about drivers' habits as well as provide immediate safety warnings.
''This job is not worth dying for,'' he said. ''There is substantial room in the trucking industry for improvements in safety.''
WHAT'S NEXT
